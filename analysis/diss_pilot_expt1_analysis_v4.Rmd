---
title: "diss_pilot_expt1_analysis"
author: "Katie"
date: "10/17/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lme4)
library(lmerTest) # p-values on lmer
source("summarySE.R")
library(corrplot)
library(plyr) # for ddply, calculating means for histograms
library(apaTables) # for apa.cor.table
#library(ggpubr) # for balloon plot

# differences in avgs btw groups
# hierarchical: differences btw groups, controlling for participant
```

```{r import data}
dir_proj <- here::here()
dir_data <- fs::path(dir_proj, "data")

df_v1n6 = read.csv(fs::path(dir_data, "2019-10-04_diss-pilot-expt1_df-users-items_v1n6.csv"), header=TRUE)
df_v2n48 = read.csv(fs::path(dir_data, "2019-10-31_diss-pilot-expt1_df-users-items_v2n48.csv"), header=TRUE)
df_v2n48_users = read.csv(fs::path(dir_data, "2019-10-31_diss-pilot-expt1_df-users-items_v2n48_users.csv"), header=TRUE)
df_v3n36 = read.csv(fs::path(dir_data, "2019-11-01_diss-pilot-expt1_df-users-items_v3n36.csv"), header=TRUE)
df_v3n36_users = read.csv(fs::path(dir_data, "2019-11-01_diss-pilot-expt1_df-users-items_v3n36_users.csv"), header=TRUE)

## v4n48
df_v4n48 = read.csv(fs::path(dir_data, "2020-02-07_diss-pilot-expt1_df-users-items_v4n48.csv"), header=TRUE)
df_v4n48_users = read.csv(fs::path(dir_data, "2020-02-07_diss-pilot-expt1_df-users-items_v4n48_users.csv"), header=TRUE)

# drop returned
df_v2n48_users <- filter(df_v2n48_users, status!="RETURNED"); nrow(df_v2n48_users) # 50
df_v3n36_users <- filter(df_v3n36_users, status!="RETURNED"); nrow(df_v3n36_users) # 37
df_v2n48 <- filter(df_v2n48, status!="RETURNED")
df_v3n36 <- filter(df_v3n36, status!="RETURNED")

## v4n48
df_v4n48_users <- filter(df_v4n48_users, status!="RETURNED" & status!="TIMED-OUT"); nrow(df_v4n48_users) # 48
df_v4n48 <- filter(df_v4n48, status!="RETURNED" & status!="TIMED-OUT")


# Create new dfs  # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

#TODO fix so no error; upon import, treating all text areas as factors instead of character vectors

v2FactCols <- c("effectivenessRestudy", 
                "effectivenessGenerate", 
                "chosenStrategy", 
                "effectivenessChosenStrategy", 
                "effort", 
                "assessmentBelief", 
                "directionOfChange", 
                "changeRelativeToOutcome")

v2NumCols <- c("age",
               "effectivenessRestudy_num", 
               "effectivenessGenerate_num", 
               "diff_assessmentBeliefRG_num", 
               "effectivenessChosenStrategy_num", 
               "directionOfChange_num", 
               "changeRelativeToOutcome_num")

v4FactCols <- c("effectivenessRestudy", 
                "effortRestudy",
                "effectivenessGenerate", 
                "effortGenerate",
                "chosenStrategy", 
                "effectivenessChosenStrategy", 
                "effortChosenStrategy",
                "effort", 
                "assessmentBelief", 
                "directionOfChange", 
                "changeRelativeToOutcome")

v4NumCols <- c("age",
               "effectivenessRestudy_num", 
               "effortRestudy_num",
               "howManyRestudy",
               "effectivenessGenerate_num", 
               "effortGenerate_num",
               "howManyGenerate",
               "diff_assessmentBeliefRG_num", 
               "effectivenessChosenStrategy_num", 
               "effortChosenStrategy_num",
               "howManyChosenStrategy",
               "effort_num",
               "directionOfChange_num", 
               "changeRelativeToOutcome_num")

df_v2n48_users[,v2FactCols] <- as.factor(NA)
df_v2n48_users[,v2NumCols] <- as.numeric(NA)
df_v2n48_v3n36_users = union(df_v2n48_users, df_v3n36_users)

df_v2n48[,v2FactCols] <- as.factor(NA)
df_v2n48[,v2NumCols] <- as.numeric(NA)
df_v2n48_v3n36 = union(df_v2n48, df_v3n36)

## v4n48
df_v2n48_users[,v4FactCols] <- as.factor(NA)
df_v2n48_users[,v4NumCols] <- as.numeric(NA)
df_v2n48[,v4FactCols] <- as.factor(NA)
df_v2n48[,v4NumCols] <- as.numeric(NA)

# drop excluded  # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

# calculate summary stats across group for exclusion
m_restudyScore <- mean(df_v2n48_v3n36_users$interventionStrategyRestudyScoreRound1, na.rm=T); m_restudyScore # 8.7
s_restudyScore <- sd(df_v2n48_v3n36_users$interventionStrategyRestudyScoreRound1, na.rm=T); s_restudyScore # 2

## v4n48
m_restudyScore <- mean(df_v4n48_users$interventionStrategyRestudyScoreRound1, na.rm=T); m_restudyScore # 9.4
s_restudyScore <- sd(df_v4n48_users$interventionStrategyRestudyScoreRound1, na.rm=T); s_restudyScore # 1.05

# drop at user level (restudyScore 3 SD below mean)
df_v2n48_v3n36_users <- filter(df_v2n48_v3n36_users, interventionStrategyRestudyScoreRound1 >= m_restudyScore - 3*s_restudyScore); nrow(df_v2n48_v3n36_users) # 82
df_v2n48_users <- filter(df_v2n48_users, interventionStrategyRestudyScoreRound1 >= m_restudyScore - 3*s_restudyScore); nrow(df_v2n48_users) # 48
df_v3n36_users <- filter(df_v3n36_users, interventionStrategyRestudyScoreRound1 >= m_restudyScore - 3*s_restudyScore); nrow(df_v3n36_users) # 34

## v4n48
df_v4n48_users <- filter(df_v4n48_users, interventionStrategyRestudyScoreRound1 >= m_restudyScore - 3*s_restudyScore); nrow(df_v4n48_users) # 47


# drop at item level
df_v2n48_v3n36 <- filter(df_v2n48_v3n36, prolificId %in% df_v2n48_v3n36_users$prolificId)
df_v2n48 <- filter(df_v2n48, prolificId %in% df_v2n48_users$prolificId)
df_v3n36 <- filter(df_v3n36, prolificId %in% df_v3n36_users$prolificId)

## v4n48
df_v4n48 <- filter(df_v4n48, prolificId %in% df_v4n48_users$prolificId); nrow(df_v4n48)/40

```


```{r wrangle data}

# Update variable types # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

df_v2n48_v3n36_users$condition <- factor(df_v2n48_v3n36_users$condition,
                                         levels=c(0,1),
                                         labels=c("control", "expt"))

df_v2n48_v3n36$condition <- factor(df_v2n48_v3n36$condition,
                                         levels=c(0,1),
                                         labels=c("control", "expt"))

## v4n48
df_v4n48_users$condition <- factor(df_v4n48_users$condition,
                                         levels=c(0,1),
                                         labels=c("control", "expt"))

df_v4n48$condition <- factor(df_v4n48$condition,
                                         levels=c(0,1),
                                         labels=c("control", "expt"))

# Create new variables # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

# feedback type (none, equal, restudy, generate)
df_v2n48_v3n36_users$feedback <- factor(ifelse(
  df_v2n48_v3n36_users$condition=="control", "none",
  ifelse(df_v2n48_v3n36_users$interventionOutcome=="equal", "equal",
         ifelse(df_v2n48_v3n36_users$interventionOutcome=="restudy", "restudy", "generate"))))

df_v2n48_v3n36$feedback <- factor(ifelse(
  df_v2n48_v3n36$condition=="control", "none",
  ifelse(df_v2n48_v3n36$interventionOutcome=="equal", "equal",
         ifelse(df_v2n48_v3n36$interventionOutcome=="restudy", "restudy", "generate"))))
                                                        
## v4n48
df_v4n48_users$feedback <- factor(ifelse(
  df_v4n48_users$condition=="control", "none",
  ifelse(df_v4n48_users$interventionOutcome=="equal", "equal",
         ifelse(df_v4n48_users$interventionOutcome=="restudy", "restudy", "generate"))))

df_v4n48$feedback <- factor(ifelse(
  df_v4n48$condition=="control", "none",
  ifelse(df_v4n48$interventionOutcome=="equal", "equal",
         ifelse(df_v4n48$interventionOutcome=="restudy", "restudy", "generate"))))

# check above
# df_v2n48_v3n36_users[c("condition", "interventionOutcome", "feedback")]

#effort rating; Carey 2010 Verbal label tables
# effortRating <- c(
#   "greatdeal" = 77,
#   "alot" = 55,
#   "moderate" = 43,
#   "alittle" = 12,
#   "not" = 0
# )
# 
# df_v3n36_users$effort_num <- effortRating[as.character(df_v3n36_users$effort)]

# which exceeded expectations more?
df_v2n48_v3n36_users$diff_interventionStrategyScoreExceedPrediction <- df_v2n48_v3n36_users$diff_interventionRestudyScoreToPrediction - 
  df_v2n48_v3n36_users$diff_interventionGenerateScoreToPrediction

df_v3n36_users$diff_interventionStrategyScoreExceedPrediction <- df_v3n36_users$diff_interventionRestudyScoreToPrediction - 
  df_v3n36_users$diff_interventionGenerateScoreToPrediction

## v4n48
df_v4n48_users$diff_interventionStrategyScoreExceedPrediction <- df_v4n48_users$diff_interventionRestudyScoreToPrediction - 
  df_v4n48_users$diff_interventionGenerateScoreToPrediction


# scale predictions to be on the same scale as effectiveness ratings

scaling_constant <- 10/1.69

df_v3n36_users$changeBeliefRG_num <- df_v3n36_users$diff_assessmentBeliefRG_num - (df_v3n36_users$diff_interventionPredictRG / scaling_constant)

## v4n48
df_v4n48_users$changeBeliefRG_num <- df_v4n48_users$diff_assessmentBeliefRG_num - (df_v4n48_users$diff_interventionPredictRG / scaling_constant)


# approximate behavioral buckets

df_v2n48_v3n36$assessmentStrategyGenerated <- ifelse(df_v2n48_v3n36$assessmentStrategyRevealLatency > 2000, "generated", "skipped")

df_v2n48_v3n36$assessmentStrategyRestudied <- ifelse(df_v2n48_v3n36$assessmentStrategyMoveOnLatency > 2000, "restudied", "skipped")

df_v2n48_v3n36$assessmentStrategyGenerated_num <- ifelse(df_v2n48_v3n36$assessmentStrategyRevealLatency > 2000, 1, 0)

df_v2n48_v3n36$assessmentStrategyRestudied_num <- ifelse(df_v2n48_v3n36$assessmentStrategyMoveOnLatency > 2000, 1, 0)

df_v2n48_v3n36$assessmentStrategyNoneGenResBoth <- factor(with(df_v2n48_v3n36, interaction(assessmentStrategyGenerated, assessmentStrategyRestudied)))

## v4n48
df_v4n48$assessmentStrategyGenerated <- ifelse(df_v4n48$assessmentStrategyRevealLatency > 2000, "generated", "skipped")

df_v4n48$assessmentStrategyRestudied <- ifelse(df_v4n48$assessmentStrategyMoveOnLatency > 2000, "restudied", "skipped")

df_v4n48$assessmentStrategyGenerated_num <- ifelse(df_v4n48$assessmentStrategyRevealLatency > 2000, 1, 0)

df_v4n48$assessmentStrategyRestudied_num <- ifelse(df_v4n48$assessmentStrategyMoveOnLatency > 2000, 1, 0)

df_v4n48$assessmentStrategyNoneGenResBoth <- factor(with(df_v4n48, interaction(assessmentStrategyGenerated, assessmentStrategyRestudied)))


# reorder variable levels

df_v4n48_users$interventionPrediction <- factor(df_v4n48_users$interventionPrediction, levels = c("generate", "equal", "restudy"))
df_v4n48_users$interventionOutcome <- factor(df_v4n48_users$interventionOutcome, levels = c("generate", "equal", "restudy"))
df_v4n48_users$assessmentBelief <- factor(df_v4n48_users$assessmentBelief, levels = c("generate", "equal", "restudy"))

# drop unused factor levels
df_v4n48 <- droplevels(df_v4n48)
df_v4n48_users <- droplevels(df_v4n48_users)
```


## Research questions


### Beliefs across conditions
Predictions 

```{r Participants predicted theyd score highest with Restudy (tables)}

# predictions
# restudy 0-10
# generate 0-10

# n48
predTbl <- addmargins(table(df_v2n48_users$interventionPrediction)); predTbl
predTbl / predTbl["Sum"]


# n36
predTbl <- addmargins(table(df_v3n36_users$interventionPrediction)); predTbl
predTbl / predTbl["Sum"]

# both
predTbl <- addmargins(table(df_v2n48_v3n36_users$interventionPrediction)); predTbl
predTbl / predTbl["Sum"]

# of 82 people, 69 make predictions for both
# of those 69...
# 68% predicted restudy (47/69)
# 12% predicted generate (8/69)
# 20% predicted equal (14/69)

## v4n48
predTbl <- addmargins(table(df_v4n48_users$interventionPrediction)); predTbl
predTbl / predTbl["Sum"]

```
Overall, 66% of participants think restudy>generate, revealed by their predicted scores out of 10 for each of the study strategies. 

```{r No pre-intervention differences by condition in score predictions (histograms)}


mu.interventionPredictRestudy <- ddply(df_v2n48_v3n36_users, "condition", summarise, grp.mean=mean(interventionPredictRestudy, na.rm = TRUE)); mu.interventionPredictRestudy
mu.interventionPredictGenerate <- ddply(df_v2n48_v3n36_users, "condition", summarise, grp.mean=mean(interventionPredictGenerate, na.rm = TRUE)); mu.interventionPredictGenerate


ggplot(df_v2n48_v3n36_users, aes(x=interventionPredictRestudy, fill=condition, color=condition)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Predicted score for restudy strategy", 
                     breaks=seq(0,10,1), limits=c(0,10)) + 
  scale_y_continuous(name="Count", limits=c(0,15)) +
  geom_vline(data=mu.interventionPredictRestudy,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")

ggplot(df_v2n48_v3n36_users, aes(x=interventionPredictGenerate, fill=condition, color=condition)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Predicted score for generate strategy",
                     breaks=seq(0,10,1), limits=c(0,10))+ 
  scale_y_continuous(name="Count", limits=c(0,15))+
  geom_vline(data=mu.interventionPredictGenerate,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")

## v4n48
mu.interventionPredictRestudy <- ddply(df_v4n48_users, "condition", summarise, grp.mean=mean(interventionPredictRestudy, na.rm = TRUE)); mu.interventionPredictRestudy
mu.interventionPredictGenerate <- ddply(df_v4n48_users, "condition", summarise, grp.mean=mean(interventionPredictGenerate, na.rm = TRUE)); mu.interventionPredictGenerate


ggplot(df_v4n48_users, aes(x=interventionPredictRestudy, fill=condition, color=condition)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Predicted score for restudy strategy", 
                     breaks=seq(0,10,1), limits=c(0,10)) + 
  scale_y_continuous(name="Count", limits=c(0,15)) +
  geom_vline(data=mu.interventionPredictRestudy,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")

ggplot(df_v4n48_users, aes(x=interventionPredictGenerate, fill=condition, color=condition)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Predicted score for generate strategy",
                     breaks=seq(0,10,1), limits=c(0,10))+ 
  scale_y_continuous(name="Count", limits=c(0,15))+
  geom_vline(data=mu.interventionPredictGenerate,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")

```

The two conditions make similar predictions: m~=4.4 for restudy, and m~=2.7 for generate. 
(And expt group is more pro-restudy than control, which is great; conservative to hypothesis)


Intervention learning scores (feedback)

```{r Participants actually did best on Generate}

# how did they actually score?
# restudy 0-10
# generate 0-10

outTbl <- addmargins(table(df_v2n48_v3n36_users$interventionOutcome)); outTbl
outTbl / outTbl["Sum"]

# of 82 people, all have scores
# 26% got restudy (21/69)
# 52% got generate (43/69)
# 22% got equal (18/69)

# v4n48
outTbl <- addmargins(table(df_v4n48_users$interventionOutcome)); outTbl
outTbl / outTbl["Sum"]

# mean prediction by prediction
mu.interventionPredictRestudy <- filter(df_v2n48_v3n36_users, !is.na(interventionPrediction)) %>% ddply("interventionPrediction", summarise, grp.mean=mean(interventionPredictRestudy, na.rm = TRUE)); mu.interventionPredictRestudy

mu.interventionPredictGenerate <- filter(df_v2n48_v3n36_users, !is.na(interventionPrediction)) %>% ddply("interventionPrediction", summarise, grp.mean=mean(interventionPredictGenerate, na.rm = TRUE)); mu.interventionPredictGenerate

filter(df_v2n48_v3n36_users, !is.na(interventionPrediction)) %>%
  ggplot(aes(x=interventionPredictRestudy, fill=interventionPrediction, color=interventionPrediction)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Prediction for restudy strategy", 
                     breaks=seq(0,10,1), limits=c(0,10)) + 
  scale_y_continuous(name="Count", limits=c(0,15)) +
  geom_vline(data=mu.interventionPredictRestudy,
             aes(xintercept=grp.mean, color=interventionPrediction),
             linetype="dashed")

filter(df_v2n48_v3n36_users, !is.na(interventionPrediction)) %>% ggplot(aes(x=interventionPredictGenerate, fill=interventionPrediction, color=interventionPrediction)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Prediction for generate strategy",
                     breaks=seq(0,10,1), limits=c(0,10))+ 
  scale_y_continuous(name="Count", limits=c(0,15))+
  geom_vline(data=mu.interventionPredictGenerate,
             aes(xintercept=grp.mean, color=interventionPrediction),
             linetype="dashed")

# mean score by prediction
mu.interventionTestRestudyScore <- filter(df_v2n48_v3n36_users, !is.na(interventionPrediction)) %>% ddply("interventionPrediction", summarise, grp.mean=mean(interventionTestRestudyScore, na.rm = TRUE)); mu.interventionTestRestudyScore

mu.interventionTestGenerateScore <- filter(df_v2n48_v3n36_users, !is.na(interventionPrediction)) %>% ddply("interventionPrediction", summarise, grp.mean=mean(interventionTestGenerateScore, na.rm = TRUE)); mu.interventionTestGenerateScore

filter(df_v2n48_v3n36_users, !is.na(interventionPrediction)) %>%
  ggplot(aes(x=interventionTestRestudyScore, fill=interventionPrediction, color=interventionPrediction)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Actual score for restudy strategy", 
                     breaks=seq(0,10,1), limits=c(0,10)) + 
  scale_y_continuous(name="Count", limits=c(0,15)) +
  geom_vline(data=mu.interventionTestRestudyScore,
             aes(xintercept=grp.mean, color=interventionPrediction),
             linetype="dashed")

filter(df_v2n48_v3n36_users, !is.na(interventionPrediction)) %>% ggplot(aes(x=interventionTestGenerateScore, fill=interventionPrediction, color=interventionPrediction)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Actual score for generate strategy",
                     breaks=seq(0,10,1), limits=c(0,10))+ 
  scale_y_continuous(name="Count", limits=c(0,15))+
  geom_vline(data=mu.interventionTestGenerateScore,
             aes(xintercept=grp.mean, color=interventionPrediction),
             linetype="dashed")


# mean score by condition
mu.interventionTestRestudyScore <-  ddply(df_v2n48_v3n36_users, "condition", summarise, grp.mean=mean(interventionTestRestudyScore, na.rm = TRUE)); mu.interventionTestRestudyScore

mu.interventionTestGenerateScore <- ddply(df_v2n48_v3n36_users, "condition", summarise, grp.mean=mean(interventionTestGenerateScore, na.rm = TRUE)); mu.interventionTestGenerateScore

  ggplot(df_v2n48_v3n36_users, aes(x=interventionTestRestudyScore, fill=condition, color=condition)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Actual score for restudy strategy", 
                     breaks=seq(0,10,1), limits=c(0,10)) + 
  scale_y_continuous(name="Count", limits=c(0,15)) +
  geom_vline(data=mu.interventionTestRestudyScore,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")

ggplot(df_v2n48_v3n36_users, aes(x=interventionTestGenerateScore, fill=condition, color=condition)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Actual score for generate strategy",
                     breaks=seq(0,10,1), limits=c(0,10))+ 
  scale_y_continuous(name="Count", limits=c(0,15))+
  geom_vline(data=mu.interventionTestGenerateScore,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")


## v4n48
# mean prediction by prediction
mu.interventionPredictRestudy <- filter(df_v4n48_users, !is.na(interventionPrediction)) %>% ddply("interventionPrediction", summarise, grp.mean=mean(interventionPredictRestudy, na.rm = TRUE)); mu.interventionPredictRestudy

mu.interventionPredictGenerate <- filter(df_v4n48_users, !is.na(interventionPrediction)) %>% ddply("interventionPrediction", summarise, grp.mean=mean(interventionPredictGenerate, na.rm = TRUE)); mu.interventionPredictGenerate

filter(df_v4n48_users, !is.na(interventionPrediction)) %>%
  ggplot(aes(x=interventionPredictRestudy, fill=interventionPrediction, color=interventionPrediction)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Prediction for restudy strategy", 
                     breaks=seq(0,10,1), limits=c(0,10)) + 
  scale_y_continuous(name="Count", limits=c(0,15)) +
  geom_vline(data=mu.interventionPredictRestudy,
             aes(xintercept=grp.mean, color=interventionPrediction),
             linetype="dashed")

filter(df_v4n48_users, !is.na(interventionPrediction)) %>% ggplot(aes(x=interventionPredictGenerate, fill=interventionPrediction, color=interventionPrediction)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Prediction for generate strategy",
                     breaks=seq(0,10,1), limits=c(0,10))+ 
  scale_y_continuous(name="Count", limits=c(0,15))+
  geom_vline(data=mu.interventionPredictGenerate,
             aes(xintercept=grp.mean, color=interventionPrediction),
             linetype="dashed")

# mean score by prediction
mu.interventionTestRestudyScore <- filter(df_v4n48_users, !is.na(interventionPrediction)) %>% ddply("interventionPrediction", summarise, grp.mean=mean(interventionTestRestudyScore, na.rm = TRUE)); mu.interventionTestRestudyScore

mu.interventionTestGenerateScore <- filter(df_v4n48_users, !is.na(interventionPrediction)) %>% ddply("interventionPrediction", summarise, grp.mean=mean(interventionTestGenerateScore, na.rm = TRUE)); mu.interventionTestGenerateScore

filter(df_v4n48_users, !is.na(interventionPrediction)) %>%
  ggplot(aes(x=interventionTestRestudyScore, fill=interventionPrediction, color=interventionPrediction)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Actual score for restudy strategy", 
                     breaks=seq(0,10,1), limits=c(0,10)) + 
  scale_y_continuous(name="Count", limits=c(0,15)) +
  geom_vline(data=mu.interventionTestRestudyScore,
             aes(xintercept=grp.mean, color=interventionPrediction),
             linetype="dashed")

filter(df_v4n48_users, !is.na(interventionPrediction)) %>% ggplot(aes(x=interventionTestGenerateScore, fill=interventionPrediction, color=interventionPrediction)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Actual score for generate strategy",
                     breaks=seq(0,10,1), limits=c(0,10))+ 
  scale_y_continuous(name="Count", limits=c(0,15))+
  geom_vline(data=mu.interventionTestGenerateScore,
             aes(xintercept=grp.mean, color=interventionPrediction),
             linetype="dashed")


# mean score by condition
mu.interventionTestRestudyScore <-  ddply(df_v4n48_users, "condition", summarise, grp.mean=mean(interventionTestRestudyScore, na.rm = TRUE)); mu.interventionTestRestudyScore

mu.interventionTestGenerateScore <- ddply(df_v4n48_users, "condition", summarise, grp.mean=mean(interventionTestGenerateScore, na.rm = TRUE)); mu.interventionTestGenerateScore

  ggplot(df_v4n48_users, aes(x=interventionTestRestudyScore, fill=condition, color=condition)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Actual score for restudy strategy", 
                     breaks=seq(0,10,1), limits=c(0,10)) + 
  scale_y_continuous(name="Count", limits=c(0,15)) +
  geom_vline(data=mu.interventionTestRestudyScore,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")

ggplot(df_v4n48_users, aes(x=interventionTestGenerateScore, fill=condition, color=condition)) +
  geom_histogram(alpha=0.5, position="dodge", binwidth=.5) + 
  scale_x_continuous(name="Actual score for generate strategy",
                     breaks=seq(0,10,1), limits=c(0,10))+ 
  scale_y_continuous(name="Count", limits=c(0,15))+
  geom_vline(data=mu.interventionTestGenerateScore,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")



```

```{r There is in fact a relationship between participants predictions and their outcomes (table chisq)}

# chisquared contingency test
# are prediction and outcome related?
predOutTbl <- table(prediction=df_v2n48_v3n36_users$interventionPrediction, outcome=df_v2n48_v3n36_users$interventionOutcome)
predOutTblMarg <- addmargins(predOutTbl); predOutTblMarg / predOutTblMarg["Sum","Sum"]
chisq.test(predOutTbl)

# SIGNIFICANT that outcomes differ by prediction (p=.02)
# those who predict equal are 2x more likely to get equal outcomes than get generate or restudy
# those who predict generate are 10x more likely to get generate than get restudy 
# those who predict restudy are 2x more likely to get generate than restudy, and 3x more likely to get generate than equal

## v4n48
predOutTbl <- table(prediction=df_v4n48_users$interventionPrediction, outcome=df_v4n48_users$interventionOutcome); predOutTbl
predOutTblMarg <- addmargins(predOutTbl); predOutTblMarg / predOutTblMarg["Sum","Sum"]; predOutTblMarg
chisq.test(predOutTbl)

# ns in v4n48; no relationship, p=0.5451

```

In fact overall, counter to participants' expectations, 51% of participants did generate>restudy. The two conditions have similar scores: m~=3.8 for restudy, and m~=4 for generate (where control did a little bit better on generate than expt).

There was no metacognitive merit dependent on outcome. Groups with one outcome were not significantly more able to predict their outcomes than others.


```{r Plotting the relationship between predictions and outcomes}
df.PO <- as.data.frame(table("prediction"=df_v2n48_v3n36_users$interventionPrediction,
      "outcome"=df_v2n48_v3n36_users$interventionOutcome))
df.PO$prediction <- factor(df.PO$prediction, levels = c("restudy", "equal", "generate"))
df.PO$outcome <- factor(df.PO$outcome, levels = c("restudy", "equal", "generate"))

df.PO %>% ggplot(aes( x = outcome , y = Freq))  + 
  geom_bar(stat="identity") + 
  facet_wrap(vars(prediction)) + theme(axis.text.x = element_text(angle = 90))


## v4n48
df.PO <- as.data.frame(table("prediction"=df_v4n48_users$interventionPrediction,
      "outcome"=df_v4n48_users$interventionOutcome))
df.PO$prediction <- factor(df.PO$prediction, levels = c("restudy", "equal", "generate"))
df.PO$outcome <- factor(df.PO$outcome, levels = c("restudy", "equal", "generate"))

df.PO %>% ggplot(aes( x = outcome , y = Freq))  + 
  geom_bar(stat="identity") + 
  facet_wrap(vars(prediction)) + theme(axis.text.x = element_text(angle = 90))
```
```{r final belief}


# v4n48
beliefTbl <- addmargins(table(df_v4n48_users$assessmentBelief)); beliefTbl
beliefTbl / beliefTbl["Sum"]

```


### Correlations among measures
```{r v4n48 TODO Exploring correlations among measures}

apa.cor.table(df_v2n48_v3n36_users[c(
  "interventionStrategyRestudyScoreRound1",
  "interventionStrategyGenerateScoreRound1",
  "interventionPredictRestudy",
  "interventionPredictGenerate",
  "interventionTestRestudyScore",
  "interventionTestGenerateScore",
  "avgAssessmentStrategyRevealLatency",
  "avgAssessmentStrategyMoveOnLatency",
  "assessmentTestScore")])



```



### Exploring Latency as a metric
Assessment behaviors (seeTranslation)
Assessment behaviors (moveOn)

```{r v4n48 TODO visualizing latencies by individual}
# figuring out how to summarize latency by individual

filter(df_v2n48_v3n36, !is.na(assessmentStrategyRevealLatency)) %>% ggplot(aes(assessmentStrategyRevealLatency, assessmentStrategyMoveOnLatency)) + geom_point() + facet_wrap(facets = vars(prolificId), ncol=13) + scale_x_continuous(limits=c(0,5050)) + scale_y_continuous(limits=c(0,5050))

# with trendline
filter(df_v2n48_v3n36, !is.na(assessmentStrategyRevealLatency)) %>% ggplot(aes(assessmentStrategyRevealLatency, assessmentStrategyMoveOnLatency)) + geom_point() + facet_wrap(facets = vars(prolificId), ncol=13) + geom_smooth(method=lm) + scale_x_continuous(limits=c(0,5050)) + scale_y_continuous(limits=c(0,5050))

```

```{r v4n48 TODO is avgLatency good? plotting avg and sd latency per individual by condition}

filter(df_v2n48_v3n36_users, !is.na(condition)) %>% ggplot(aes(avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, color=condition)) + 
  geom_point() + 
  geom_errorbar(aes(ymin=avgAssessmentStrategyMoveOnLatency-sdAssessmentStrategyMoveOnLatency, ymax=avgAssessmentStrategyMoveOnLatency+sdAssessmentStrategyMoveOnLatency), width=.2, position=position_dodge(.9)) + 
  geom_errorbarh(aes(xmin=avgAssessmentStrategyRevealLatency-sdAssessmentStrategyRevealLatency, xmax=avgAssessmentStrategyRevealLatency+sdAssessmentStrategyRevealLatency), width=.2, position=position_dodge(.9))

```

## final belief categorical

```{r condition on belief pre-post}


predTbl <- addmargins(table(df_v4n48_users$interventionPrediction)); predTbl

outTbl <- addmargins(table(df_v4n48_users$interventionOutcome)); outTbl

beliefTbl <- addmargins(table(df_v4n48_users$assessmentBelief)); beliefTbl


predTbl <- addmargins(table(df_v4n48_users$interventionPrediction, df_v4n48_users$condition)); predTbl

outTbl <- addmargins(table(df_v4n48_users$interventionOutcome, df_v4n48_users$condition)); outTbl

beliefTbl <- addmargins(table(df_v4n48_users$assessmentBelief, df_v4n48_users$condition)); beliefTbl

# histograms of pre-post categorical shifts for all, control, and expt

melt <- tidyr::gather(df_v4n48_users, key="time", value="diffRG", interventionPrediction, assessmentBelief, factor_key = TRUE) # factor_key preserves order
melt$diffRG = factor(melt$diffRG, levels=c("generate", "equal", "restudy"))

# all
melt %>% ggplot(aes(x=diffRG, color=time, fill=time)) + geom_bar(stat="count", alpha=0.5, position="identity") + theme(legend.position="bottom") 
# by condition
melt %>% ggplot(aes(x=diffRG, color=time, fill=time)) + geom_bar(stat="count", alpha=0.5, position="identity") + facet_wrap(vars(condition)) + theme(legend.position="bottom") 


```






Those in the control group tend to continue to believe restudy is better, despite having done better with generate.

```{r condition on belief stats}

# simple lm, diff in beliefs? some!
summary(lm(effectivenessGenerate_num ~ condition, df_v4n48_users)) # ns
summary(lm(effectivenessRestudy_num ~ condition, df_v4n48_users)) # .02
summary(lm(effectivenessChosenStrategy_num ~ condition, df_v4n48_users)) # ns

summary(lm(effortGenerate_num ~ condition, df_v4n48_users)) # ns
summary(lm(effortRestudy_num ~ condition, df_v4n48_users)) # ns
summary(lm(effortChosenStrategy_num ~ condition, df_v4n48_users)) # ns

summary(lm(howManyGenerate ~ condition, df_v4n48_users)) # ns
summary(lm(howManyRestudy ~ condition, df_v4n48_users)) # ns

```



```{r condition*prediction on belief}

# by condition
df_v4n48_users %>% ggplot(aes(x=assessmentBelief, color=condition, fill=condition)) + geom_bar(stat="count", alpha=0.5, position="identity") + theme(legend.position="bottom") + 
  facet_wrap(vars(interventionPrediction), labeller = "label_both")

```


```{r condition*outcome on belief, fig.width=4, fig.height=4}

# by condition
df_v4n48_users %>% ggplot(aes(x=assessmentBelief, color=condition, fill=condition)) + geom_bar(stat="count", alpha=0.5, position="identity") + theme(legend.position="bottom") + 
  facet_grid(vars(interventionOutcome), labeller = "label_both")

```


```{r condition*prediction*outcome on belief histograms, fig.width=7, fig.height=7}


# by condition
df_v4n48_users %>% ggplot(aes(x=assessmentBelief, color=condition, fill=condition)) + geom_bar(stat="count", alpha=0.5, position="identity") + theme(legend.position="bottom") + 
  facet_grid(interventionOutcome ~ interventionPrediction, labeller = "label_both")

```

```{r  condition*predicition*outcome on belief bar charts}

# effectiveness rating
# restudy 0-5
# generate 0-5
# free choice 0-5

# only have for n=35
# of those 35...

### AFTER EXCLUSIONS
# only have for n=33
# of those 33...


addmargins(table(df_v3n36_users$assessmentBelief, df_v3n36_users$condition))
table(df_v3n36_users$assessmentBelief) / 33

# people who have both? only 27?
# prediction by belief
addmargins(table(df_v3n36_users$interventionPrediction,
      df_v3n36_users$assessmentBelief)) / 27


# outcome by belief (n=33)
addmargins(table(df_v3n36_users$interventionOutcome,
      df_v3n36_users$assessmentBelief)) 
addmargins(table(df_v3n36_users$interventionOutcome,
      df_v3n36_users$assessmentBelief)) / 33

# predict * outcome * belief
addmargins(table(df_v3n36_users$interventionPrediction,
      df_v3n36_users$interventionOutcome,
      df_v3n36_users$assessmentBelief))
addmargins(table(df_v3n36_users$interventionPrediction,
      df_v3n36_users$interventionOutcome,
      df_v3n36_users$assessmentBelief))/27

## v4n48
# predict * outcome * belief * condition
table(prediction=df_v4n48_users$interventionPrediction,
      outcome=df_v4n48_users$interventionOutcome,
      belief=df_v4n48_users$assessmentBelief, 
      condition=df_v4n48_users$condition)
table(prediction=df_v4n48_users$interventionPrediction,
      outcome=df_v4n48_users$interventionOutcome,
      belief=df_v4n48_users$assessmentBelief, 
      condition=df_v4n48_users$condition)/47

# plot

df.POB <- as.data.frame(table("prediction"=df_v3n36_users$interventionPrediction,
      "outcome"=df_v3n36_users$interventionOutcome,
      "belief"=df_v3n36_users$assessmentBelief))
df.POB$prediction <- factor(df.POB$prediction, levels = c("restudy", "equal", "generate"))
df.POB$outcome <- factor(df.POB$outcome, levels = c("restudy", "equal", "generate"))
df.POB$belief <- factor(df.POB$belief, levels = c("restudy", "equal", "generate"))

#ggballoonplot(df.POB, x = "outcome", y = "belief", size = "Freq",
#              fill = "Freq", facet.by = "prediction",
#              ggtheme = theme_bw()) +
#  scale_fill_viridis_c(option = "C")

#df.POB %>% ggplot(aes( x = outcome, y = Freq))  + 
#  geom_bar(stat="identity", position=position_dodge(.9), aes(fill = belief)) + 
#  facet_wrap(vars(prediction))

df.POB %>% ggplot(aes( x = outcome , y = Freq))  + 
  geom_bar(stat="identity", aes(fill = belief)) + 
  facet_wrap(vars(prediction)) + theme(axis.text.x = element_text(angle = 90))


## v4n48
df.POB <- as.data.frame(table("prediction"=df_v4n48_users$interventionPrediction,
      "outcome"=df_v4n48_users$interventionOutcome,
      "belief"=df_v4n48_users$assessmentBelief, 
      condition=df_v4n48_users$condition))
df.POB$prediction <- factor(df.POB$prediction, levels = c("restudy", "equal", "generate"))
df.POB$outcome <- factor(df.POB$outcome, levels = c("restudy", "equal", "generate"))
df.POB$belief <- factor(df.POB$belief, levels = c("restudy", "equal", "generate"))

df.POB %>% ggplot(aes( x = outcome , y = Freq))  + 
  geom_bar(stat="identity", aes(fill = belief)) + 
  facet_wrap(vars(condition, prediction)) + theme(axis.text.x = element_text(angle = 90))


```

## final belief continuous
```{r condition on continuous belief pre-post}

# histograms of pre-post shifts for all, control, and expt

melt <- tidyr::gather(df_v4n48_users, key="time", value="diffRG", diff_interventionPredictRG, diff_assessmentBeliefRG_num, factor_key = TRUE) # factor_key preserves order

# all
melt %>% ggplot(aes(x=diffRG, color=time, fill=time)) + geom_histogram(alpha=0.5, position="identity", binwidth=.25) + theme(legend.position="bottom") +geom_density(alpha=0.6) # with Kernel Density Plot (gaussian kernel, width=bw)

# by condition
melt %>% ggplot(aes(x=diffRG, color=time, fill=time)) + geom_histogram(alpha=0.5, position="identity", binwidth=.25) + facet_wrap(vars(condition)) + theme(legend.position="bottom") +geom_density(alpha=0.6) # with Kernel Density Plot (gaussian kernel, width=bw)


```

```{r condition*prediction on continuous belief}


# by condition
df_v4n48_users %>% ggplot(aes(x=diff_assessmentBeliefRG_num, color=condition, fill=condition)) + geom_histogram(alpha=0.5, position="identity", binwidth=.25) + facet_wrap(vars(interventionPrediction), labeller="label_both") + theme(legend.position="bottom")


```

```{r condition*outcome on continuous belief, fig.height=4, fig.width=4}


# by condition
df_v4n48_users %>% ggplot(aes(x=diff_assessmentBeliefRG_num, color=condition, fill=condition)) + geom_histogram(alpha=0.5, position="identity", binwidth=.25) + facet_grid(vars(interventionOutcome), labeller="label_both") + theme(legend.position="bottom")


```

```{r condition*prediction*outcome on continuous belief, fig.height=4, fig.width=4}


# by condition
df_v4n48_users %>% ggplot(aes(x=diff_assessmentBeliefRG_num, color=condition, fill=condition)) + geom_histogram(alpha=0.5, position="identity", binwidth=.25) + facet_grid(interventionOutcome~interventionPrediction, labeller="label_both") + theme(legend.position="bottom")


```

# behaviors

```{r intervention results by condition (effect of feedback)}
## v4n48
# scatter
filter(df_v4n48_users, !is.na(condition)) %>% ggplot(aes(avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, color=condition)) + 
  geom_point()

# histograms

mu.avgAssessmentStrategyRevealLatency <- filter(df_v4n48_users, !is.na(condition)) %>% ddply("condition", summarise, grp.mean=mean(avgAssessmentStrategyRevealLatency, na.rm = TRUE)); mu.avgAssessmentStrategyRevealLatency

mu.avgAssessmentStrategyMoveOnLatency <- filter(df_v4n48_users, !is.na(condition)) %>% ddply("condition", summarise, grp.mean=mean(avgAssessmentStrategyMoveOnLatency, na.rm = TRUE)); mu.avgAssessmentStrategyMoveOnLatency

for (n in seq(500,1500,100))
{
plot <- filter(df_v4n48_users, !is.na(condition)) %>% ggplot(aes(avgAssessmentStrategyRevealLatency, fill=condition, color=condition)) + 
  geom_histogram(alpha=0.5, position="identity", binwidth=n) +
  geom_vline(data=mu.avgAssessmentStrategyRevealLatency,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")
print(plot)
}

for (n in seq(500,1500,100))
{
plot <- filter(df_v4n48_users, !is.na(condition)) %>% ggplot(aes(avgAssessmentStrategyMoveOnLatency, fill=condition, color=condition)) + 
  geom_histogram(alpha=0.5, position="identity", binwidth=n) +
  geom_vline(data=mu.avgAssessmentStrategyMoveOnLatency,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")
print(plot)
}

table(filter(df_v4n48_users, !is.na(condition))$condition) # n=60 expt, n=19 control

# means and errorbars, Latency means
melt <- tidyr::gather(df_v4n48_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(condition, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "condition", y = "mean latencies")


# simple lm, diff in mean latencies? no.
summary(lm(avgAssessmentStrategyRevealLatency ~ condition, df_v4n48_users)) # ns
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition, df_v4n48_users)) # ns
#summary(lm(totalL ~ condition, df_v4n48_users)) # ns

# simple lm, diff in conjunction of latencies? 
# short*long, median split

# diff in sd latencies? ...yes?
summary(lm(sdAssessmentStrategyRevealLatency ~ condition, df_v4n48_users)) # ns
summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition, df_v4n48_users)) # ns


#summary(lm(avgAssessmentStrategyRevealLatency ~ condition * , df_v4n48_users))


# lmer?
#summary(lmer(assessmentStrategyRevealLatency ~ condition + assessmentTestAccuracy + (1 | prolificId), df_v4n48))
#summary(lmer(assessmentStrategyMoveOnLatency ~ condition + assessmentTestAccuracy + (1 | prolificId), df_v4n48))


```
```{r different varianaces by group in avgLatency?}

# f test to compare two variances
# null: variances of two populations are equal
# alt: variances are not equal
# http://www.endmemo.com/program/R/ftest.php



var.test(effectivenessRestudy_num ~ condition, df_v4n48_users) # ns
var.test(effectivenessGenerate_num ~ condition, df_v4n48_users) # ns
var.test(effectivenessChosenStrategy_num ~ condition, df_v4n48_users) # ns

var.test(effortRestudy_num ~ condition, df_v4n48_users) # ns
var.test(effortGenerate_num ~ condition, df_v4n48_users) # ns
var.test(effortChosenStrategy_num ~ condition, df_v4n48_users) # ns

var.test(avgAssessmentStrategyRevealLatency ~ condition, df_v4n48_users) # ns
var.test(avgAssessmentStrategyMoveOnLatency ~ condition, df_v4n48_users) # ns

var.test(howManyRestudy ~ condition, df_v4n48_users) # ns
var.test(howManyGenerate ~ condition, df_v4n48_users) # ns

var.test(assessmentTestScore ~ condition, df_v4n48) # p =0.001014


```

# test scores
```{r}

# histograms
mu.interventionTestScore <- filter(df_v4n48_users, !is.na(condition)) %>% ddply("condition", summarise, grp.mean=mean(interventionTestScore, na.rm = TRUE)); mu.interventionTestScore

mu.assessmentTestScore <- filter(df_v4n48_users, !is.na(condition)) %>% ddply("condition", summarise, grp.mean=mean(assessmentTestScore, na.rm = TRUE)); mu.assessmentTestScore


filter(df_v4n48_users, !is.na(condition)) %>% ggplot(aes(assessmentTestScore, fill=condition, color=condition)) + 
  geom_histogram(alpha=0.5, position="dodge") +
  geom_vline(data=mu.assessmentTestScore,
             aes(xintercept=grp.mean, color=condition),
             linetype="dashed")

# means and errorbars, Intervention test score
melt <- tidyr::gather(df_v4n48_users, key="measures", value="mean", interventionTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "measures"), na.rm=TRUE, conf.interval=0.95); means

means %>% ggplot(aes(condition, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "condition", y="interventionTestScore")

# means and errorbars, Assessment test score
melt <- tidyr::gather(df_v4n48_users, key="measures", value="mean", assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "measures"), na.rm=TRUE, conf.interval=0.95); means

filter(means, measures=="assessmentTestScore") %>% ggplot(aes(condition, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "condition", y="assessmentTestScore")

# diff in learning outcomes? no.
summary(lm(assessmentTestScore ~ condition, df_v4n48_users)) # ns


```


```{r effect of feedback (4 categorical)}



# scatter
filter(df_v2n48_v3n36_users, !is.na(interventionOutcome)) %>% ggplot(aes(avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, color=feedback)) + 
  geom_point() 

# histograms

filter(df_v2n48_v3n36_users, !is.na(feedback)) %>% ggplot(aes(avgAssessmentStrategyRevealLatency, fill=feedback, color=feedback)) + 
  geom_histogram(alpha=0.5, position="dodge") 

filter(df_v2n48_v3n36_users, !is.na(feedback)) %>% ggplot(aes(avgAssessmentStrategyMoveOnLatency, fill=feedback, color=feedback)) + 
  geom_histogram(alpha=0.5, position="dodge")

filter(df_v2n48_v3n36_users, !is.na(feedback)) %>% ggplot(aes(assessmentTestScore, fill=feedback, color=feedback)) + 
  geom_histogram(alpha=0.5, position="dodge")
  

# means and errorbars, Latency means
melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("feedback", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, !is.na(feedback)) %>% ggplot(aes(feedback, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "intervention outcome", y = "mean latencies")

# means and errorbars, Assessment test score
melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("feedback", "measures"), na.rm=TRUE, conf.interval=0.95); means

filter(means, measures=="assessmentTestScore" & !is.na(feedback)) %>% ggplot(aes(feedback, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentTestScore") 


# simple lm, diff in mean latencies? no.
summary(lm(avgAssessmentStrategyRevealLatency ~ feedback, df_v2n48_v3n36_users)) # ?
summary(lm(avgAssessmentStrategyMoveOnLatency ~ feedback, df_v2n48_v3n36_users)) # p<.02, equal>none

# diff in learning outcomes? no.
summary(lm(assessmentTestScore ~ feedback, df_v2n48_v3n36_users)) # ns


## v4n48
# scatter
filter(df_v4n48_users, !is.na(interventionOutcome)) %>% ggplot(aes(avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, color=feedback)) + 
  geom_point() 

# histograms

filter(df_v4n48_users, !is.na(feedback)) %>% ggplot(aes(avgAssessmentStrategyRevealLatency, fill=feedback, color=feedback)) + 
  geom_histogram(alpha=0.5, position="dodge") 

filter(df_v4n48_users, !is.na(feedback)) %>% ggplot(aes(avgAssessmentStrategyMoveOnLatency, fill=feedback, color=feedback)) + 
  geom_histogram(alpha=0.5, position="dodge")

filter(df_v4n48_users, !is.na(feedback)) %>% ggplot(aes(assessmentTestScore, fill=feedback, color=feedback)) + 
  geom_histogram(alpha=0.5, position="dodge")
  

# means and errorbars, Latency means
melt <- tidyr::gather(df_v4n48_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("feedback", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, !is.na(feedback)) %>% ggplot(aes(feedback, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "intervention outcome", y = "mean latencies")

# means and errorbars, Assessment test score
melt <- tidyr::gather(df_v4n48_users, key="measures", value="mean", assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("feedback", "measures"), na.rm=TRUE, conf.interval=0.95); means

filter(means, measures=="assessmentTestScore" & !is.na(feedback)) %>% ggplot(aes(feedback, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentTestScore") 


# simple lm, diff in beliefs? some!
summary(lm(effectivenessGenerate_num ~ feedback, df_v4n48_users)) # ns
summary(lm(effectivenessRestudy_num ~ feedback, df_v4n48_users)) # .02
summary(lm(effectivenessChosenStrategy_num ~ feedback, df_v4n48_users)) # ns

summary(lm(effortGenerate_num ~ feedback, df_v4n48_users)) # ns
summary(lm(effortRestudy_num ~ feedback, df_v4n48_users)) # ns
summary(lm(effortChosenStrategy_num ~ feedback, df_v4n48_users)) # ns

summary(lm(howManyGenerate ~ feedback, df_v4n48_users)) # ns
summary(lm(howManyRestudy ~ feedback, df_v4n48_users)) # ns

# simple lm, diff in mean latencies? no.
summary(lm(avgAssessmentStrategyRevealLatency ~ feedback, df_v4n48_users)) # ?
summary(lm(avgAssessmentStrategyMoveOnLatency ~ feedback, df_v4n48_users)) # p<.02, equal>none

# diff in learning outcomes? no.
summary(lm(assessmentTestScore ~ feedback, df_v4n48_users)) # ns

```


```{r effect of feedback moderated by outcome (3 categorical)}

# scatter
filter(df_v2n48_v3n36_users, !is.na(interventionOutcome)) %>% ggplot(aes(avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, color=condition)) + 
  geom_point() + facet_wrap(facets = vars(interventionOutcome), ncol=2)

# histograms

filter(df_v2n48_v3n36_users, !is.na(condition)) %>% ggplot(aes(avgAssessmentStrategyRevealLatency, fill=condition, color=condition)) + 
  geom_histogram(alpha=0.5, position="dodge") + facet_wrap(facets = vars(interventionOutcome))

filter(df_v2n48_v3n36_users, !is.na(condition)) %>% ggplot(aes(avgAssessmentStrategyMoveOnLatency, fill=condition, color=condition)) + 
  geom_histogram(alpha=0.5, position="dodge") + facet_wrap(facets = vars(interventionOutcome))

filter(df_v2n48_v3n36_users, !is.na(condition)) %>% ggplot(aes(assessmentTestScore, fill=condition, color=condition)) + 
  geom_histogram(alpha=0.5, position="dodge") + facet_wrap(facets = vars(interventionOutcome))

table(df_v2n48_v3n36_users$condition, df_v2n48_v3n36_users$interventionOutcome) # n=60 expt, n=19 control

# means and errorbars, Latency means
melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "interventionOutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, !is.na(interventionOutcome)) %>% ggplot(aes(interventionOutcome, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "intervention outcome", y = "mean latencies") + facet_wrap(facet=vars(condition))

# means and errorbars, Assessment test score
# melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", assessmentStrategyTotalLatency, factor_key = TRUE) # factor_key preserves order
# means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "interventionOutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
# 
# filter(means, !is.na(interventionOutcome)) %>% ggplot(aes(interventionOutcome, mean)) + 
#     geom_point(position=position_dodge(.9), stat="identity") + 
#     geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
#     theme(axis.text.x = element_text(angle = 90)) +
#     labs(x = "assessmentStrategyTotalLatency") + facet_wrap(facet=vars(condition))

# means and errorbars, Assessment test score
melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "interventionOutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means

filter(means, !is.na(interventionOutcome)) %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentTestScore") + facet_wrap(facet=vars(condition))


# simple lm, diff in mean latencies, moderated by interventionOutcome? 
summary(lm(avgAssessmentStrategyRevealLatency ~ condition * interventionOutcome, df_v2n48_v3n36_users)) #?, the experimental group spent longer on seeTranslation than control. Those in the experimental group who got generate feedback spent shorter in seeTranslation than those in the control group who got no generate feedback.
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition * interventionOutcome, df_v2n48_v3n36_users)) # p<.05, the experimental group spent longer on moveOn than control. Those in the experimental group who got generate feedback spent shorter in moveOn than those in the control group who got no generate feedback.

# simple lm, diff in conjunction of latencies? 
# short*long, median split


# diff in learning outcomes? no.
summary(lm(assessmentTestScore ~ condition * interventionOutcome, df_v2n48_v3n36_users)) # no

# diff in learning outcomes, controlling for intervention score? no.
summary(lm(assessmentTestScore ~ condition * interventionOutcome + interventionTestScore, df_v2n48_v3n36_users)) # no

# lmer?
#summary(lmer(assessmentStrategyRevealLatency ~ condition + assessmentTestAccuracy + (1 | prolificId), df_v2n48_v3n36))
#summary(lmer(assessmentStrategyMoveOnLatency ~ condition + assessmentTestAccuracy + (1 | prolificId), df_v2n48_v3n36))


```


```{r effect of feedback moderated by outcome (3 categorical) contd}
#df_gotFeedback$interventionTestScore <- df_gotFeedback$interventionTestGenerateScore + df_gotFeedback$interventionTestRestudyScore

summary(lm(avgAssessmentStrategyRevealLatency ~ interventionOutcome, df_gotFeedback)) # ?, generate spends least time before seeTranslation?
summary(lm(avgAssessmentStrategyMoveOnLatency ~ interventionOutcome, df_gotFeedback)) # p<.01, generate spends least time before moveOn
summary(lm(sdAssessmentStrategyRevealLatency ~ interventionOutcome, df_gotFeedback)) # no
summary(lm(sdAssessmentStrategyMoveOnLatency ~ interventionOutcome, df_gotFeedback)) # no
summary(lm(assessmentTestScore ~ interventionOutcome, df_gotFeedback)) # ? TREND, generate does better on test
summary(lm(assessmentTestScore ~ interventionOutcome + interventionTestScore, df_gotFeedback)) # n.s.
# Conclusion: feedback changes behaviors, and maybe outcomes

# plotting interaction?
#df_gotFeedback %>% ggplot(aes(interventionTestScore, assessmentTestScore, color=interventionOutcome)) + geom_point() + geom_smooth(method=loess)

summary(lm(effectivenessRestudy_num ~ interventionOutcome, df_v3n36_users)) # ? TREND, restudy rate restudy higher
summary(lm(effectivenessGenerate_num ~ interventionOutcome, df_v3n36_users)) # p<.03, generate rate generate higher
summary(lm(effectivenessChosenStrategy_num ~ interventionOutcome, df_v3n36_users)) # ?
summary(lm(diff_beliefs ~ interventionOutcome, df_v3n36_users)) # p<.05 generate rate generate higher than restudy
# Conclusion: feedback does change beliefs...

# Latency means
melt <- tidyr::gather(df_gotFeedback, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("interventionOutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, !is.na(interventionOutcome)) %>% ggplot(aes(interventionOutcome, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "intervention outcome", y = "mean latencies")


melt <- tidyr::gather(df_gotFeedback, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, sdAssessmentStrategyRevealLatency, sdAssessmentStrategyMoveOnLatency, assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("interventionOutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, measures=="avgAssessmentStrategyRevealLatency") %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "avgAssessmentStrategyRevealLatency")

filter(means, measures=="avgAssessmentStrategyMoveOnLatency") %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "avgAssessmentStrategyMoveOnLatency")

filter(means, measures=="sdAssessmentStrategyRevealLatency") %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "sdAssessmentStrategyRevealLatency")

filter(means, measures=="sdAssessmentStrategyMoveOnLatency") %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "sdAssessmentStrategyMoveOnLatency")

filter(means, measures=="assessmentTestScore" & !is.na(interventionOutcome)) %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentTestScore")


melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("interventionOutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means

filter(means, !is.na(interventionOutcome)) %>% ggplot(aes(interventionOutcome, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "effectivenessRestudy_num")

filter(means, measures=="effectivenessRestudy_num") %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "effectivenessRestudy_num")

filter(means, measures=="effectivenessGenerate_num") %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "effectivenessGenerate_num")

filter(means, measures=="effectivenessChosenStrategy_num") %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "effectivenessChosenStrategy_num")

filter(means, measures=="diff_beliefs") %>% ggplot(aes(interventionOutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "diff_beliefs")

```

```{r effect of feedback continuous}

df_gotFeedback <- filter(df_v2n48_v3n36_users, condition=="expt")
df_gotFeedback$diff_predict_vs_score <- df_gotFeedback$diff_predict - df_gotFeedback$diff_score

summary(lm(avgAssessmentStrategyRevealLatency ~ diff_predict_vs_score, df_gotFeedback)) # no
summary(lm(avgAssessmentStrategyMoveOnLatency ~ diff_predict_vs_score, df_gotFeedback)) # no
summary(lm(sdAssessmentStrategyRevealLatency ~ diff_predict_vs_score, df_gotFeedback)) # yes...? more generate, less variance
summary(lm(sdAssessmentStrategyMoveOnLatency ~ diff_predict_vs_score, df_gotFeedback)) # yes...? more generate, less variance
summary(lm(assessmentTestScore ~ diff_predict_vs_score, df_gotFeedback)) # no


df_gotFeedback %>% ggplot(aes(diff_predict_vs_score, avgAssessmentStrategyRevealLatency, color=diff_predict_vs_score)) + geom_point()
df_gotFeedback %>% ggplot(aes(diff_predict_vs_score, avgAssessmentStrategyMoveOnLatency, color=diff_predict_vs_score)) + geom_point()
df_gotFeedback %>% ggplot(aes(diff_predict_vs_score, sdAssessmentStrategyRevealLatency, color=diff_predict_vs_score)) + geom_point()
df_gotFeedback %>% ggplot(aes(diff_predict_vs_score, sdAssessmentStrategyMoveOnLatency, color=diff_predict_vs_score)) + geom_point()
df_gotFeedback %>% ggplot(aes(diff_predict_vs_score, assessmentTestScore, color=diff_predict_vs_score)) + geom_point()

df_v3n36_users$diff_predict_vs_score <- df_v3n36_users$diff_predict - df_v3n36_users$diff_score
summary(lm(diff_beliefs ~ diff_predict_vs_score, df_v3n36_users)) # no

```


```{r effect of feedback moderated by prediction*outcome (3x3 categorical) expt only}

df_gotFeedback$predictionbyoutcome <- factor(with(df_gotFeedback, interaction(interventionPrediction, interventionOutcome)))

summary(lm(avgAssessmentStrategyRevealLatency ~ predictionbyoutcome, df_gotFeedback)) # no
summary(lm(avgAssessmentStrategyMoveOnLatency ~ predictionbyoutcome, df_gotFeedback)) # TREND, generate feedback had shorter moveOn latency (but restudy feedback too)
summary(lm(sdAssessmentStrategyRevealLatency ~ predictionbyoutcome, df_gotFeedback)) # ?
summary(lm(sdAssessmentStrategyMoveOnLatency ~ predictionbyoutcome, df_gotFeedback)) # no
summary(lm(assessmentTestScore ~ predictionbyoutcome, df_gotFeedback)) # ?, generate feedback had higher assessmentTest scores??


df_v2n48_v3n36_users$predictionbyoutcome <- factor(with(df_v2n48_v3n36_users, interaction(interventionPrediction, interventionOutcome)))

summary(lm(avgAssessmentStrategyRevealLatency ~ predictionbyoutcome * condition, df_v2n48_v3n36_users)) # no
summary(lm(avgAssessmentStrategyMoveOnLatency ~ predictionbyoutcome * condition, df_v2n48_v3n36_users)) # TREND
summary(lm(assessmentTestScore ~ predictionbyoutcome * condition, df_v2n48_v3n36_users)) # no

melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, !is.na(predictionbyoutcome)) %>% ggplot(aes(predictionbyoutcome, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "latencies") + facet_wrap(facet=vars(condition))


### Beliefs

df_v3n36_users$predictionbyoutcome <- factor(with(df_v3n36_users, interaction(interventionPrediction, interventionOutcome)))

summary(lm(effectivenessRestudy_num ~ predictionbyoutcome, df_v3n36_users)) # no
summary(lm(effectivenessGenerate_num ~ predictionbyoutcome, df_v3n36_users)) # no
summary(lm(effectivenessChosenStrategy_num ~ predictionbyoutcome, df_v3n36_users)) # ? those who predicted Restudy initially rate their chosen strategy as more effective. Why? What strategies are they using? Can we see a difference in their descriptions?
summary(lm(diff_beliefs ~ predictionbyoutcome, df_v3n36_users)) # no


melt <- tidyr::gather(df_gotFeedback, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(predictionbyoutcome, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "latencies")

melt <- tidyr::gather(df_gotFeedback, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, sdAssessmentStrategyRevealLatency, sdAssessmentStrategyMoveOnLatency, assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, measures=="avgAssessmentStrategyRevealLatency") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "avgAssessmentStrategyRevealLatency")

filter(means, measures=="avgAssessmentStrategyMoveOnLatency") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "avgAssessmentStrategyMoveOnLatency")

filter(means, measures=="sdAssessmentStrategyRevealLatency") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "sdAssessmentStrategyRevealLatency")

filter(means, measures=="sdAssessmentStrategyMoveOnLatency") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "sdAssessmentStrategyMoveOnLatency")

filter(means, measures=="assessmentTestScore") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentTestScore")


melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means

means %>% ggplot(aes(predictionbyoutcome, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "beliefs")


melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean",  diff_beliefs, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means

filter(means, measures=="diff_beliefs") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "diff_beliefs")
```


```{r effect of feedback moderated by prediction*outcome (3x3 categorical)}

df_v2n48_v3n36_users$predictionbyoutcome <- factor(with(df_v2n48_v3n36_users, interaction(interventionPrediction, interventionOutcome)))
df_v2n48_v3n36_users$predictionbyoutcome <- factor(df_v2n48_v3n36_users$predictionbyoutcome, 
                                                   levels = c("predictEqual.equal", 
                                                              "predictRestudy.restudy",
                                                              "predictGenerate.generate",
                                                              "predictEqual.restudy", 
                                                              "predictEqual.generate",
                                                              "predictRestudy.equal",
                                                              "predictRestudy.generate", 
                                                              "predictGenerate.equal",
                                                              "predictGenerate.restudy"
                                                              ))

summary(lm(avgAssessmentStrategyRevealLatency ~ condition* predictionbyoutcome, df_v2n48_v3n36_users)) # no
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition* predictionbyoutcome, df_v2n48_v3n36_users)) # TREND
summary(lm(sdAssessmentStrategyRevealLatency ~ condition* predictionbyoutcome, df_v2n48_v3n36_users)) # ?
summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition* predictionbyoutcome, df_v2n48_v3n36_users)) # ?
summary(lm(assessmentTestScore ~ condition* predictionbyoutcome, df_v2n48_v3n36_users)) # ?

## Latencies

melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, !is.na(predictionbyoutcome)) %>% ggplot(aes(predictionbyoutcome, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "latencies") + facet_wrap(facet=vars(condition)) 


filter(means, !is.na(predictionbyoutcome) & measures=="avgAssessmentStrategyRevealLatency") %>% ggplot(aes(predictionbyoutcome, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "latencies") + facet_wrap(facet=vars(condition)) +
    scale_y_continuous(limits=c(-10000,10000))


filter(means, !is.na(predictionbyoutcome) & measures=="avgAssessmentStrategyMoveOnLatency") %>% ggplot(aes(predictionbyoutcome, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "latencies") + facet_wrap(facet=vars(condition)) +
    scale_y_continuous(limits=c(-10000,10000))


## Test

melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, !is.na(predictionbyoutcome)) %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentTestScore") + facet_wrap(facet=vars(condition)) 

### Beliefs

df_v3n36_users$predictionbyoutcome <- factor(with(df_v3n36_users, interaction(interventionPrediction, interventionOutcome)))

summary(lm(effectivenessRestudy_num ~ predictionbyoutcome, df_v3n36_users)) # no
summary(lm(effectivenessGenerate_num ~ predictionbyoutcome, df_v3n36_users)) # no
summary(lm(effectivenessChosenStrategy_num ~ predictionbyoutcome, df_v3n36_users)) # ? those who predicted Restudy initially rate their chosen strategy as more effective. Why? What strategies are they using? Can we see a difference in their descriptions?
summary(lm(diff_beliefs ~ predictionbyoutcome, df_v3n36_users)) # no


melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(predictionbyoutcome, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "latencies")

melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, sdAssessmentStrategyRevealLatency, sdAssessmentStrategyMoveOnLatency, assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, measures=="avgAssessmentStrategyRevealLatency") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "avgAssessmentStrategyRevealLatency")

filter(means, measures=="avgAssessmentStrategyMoveOnLatency") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "avgAssessmentStrategyMoveOnLatency")

filter(means, measures=="sdAssessmentStrategyRevealLatency") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "sdAssessmentStrategyRevealLatency")

filter(means, measures=="sdAssessmentStrategyMoveOnLatency") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "sdAssessmentStrategyMoveOnLatency")

filter(means, measures=="assessmentTestScore") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentTestScore")


melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means

means %>% ggplot(aes(predictionbyoutcome, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "beliefs")


melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean",  diff_beliefs, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("predictionbyoutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means

filter(means, measures=="diff_beliefs") %>% ggplot(aes(predictionbyoutcome, mean)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "diff_beliefs")
```

```{r making sense of predictors}

# prediction 

melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "interventionPrediction", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, !is.na(interventionPrediction)) %>% ggplot(aes(interventionPrediction, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "latencies") + facet_wrap(facet=vars(condition)) 

# outcome

melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "interventionOutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
filter(means, !is.na(interventionOutcome)) %>% ggplot(aes(interventionOutcome, mean, color=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "latencies") + facet_wrap(facet=vars(condition)) 


```




Assessment learning outcomes


Everyone will predict that they do better with reread 
(avg prediction reread, avg prediction generate)
Split by #/% correct or incorrect on strategy, and/or relative performance on strategies A/B 
```{r}
# remove duplicates long data
# interventionPredictRestudy
# interventionPredictGenerate
```


In fact, everyone will do better with generate (interventionTest accuracy)
```{r}
#df_v2n48_v3n36_users$
```


Expt vs. control
Intervention folks will have longer reveal latency
Split by later correct or incorrect
shorter moveOn latency?
Split by later correct or incorrect
Better assessmentTest accuracy

Expt-match-expectations vs. expt-nonmatch vs. control
Would expect those who predicted the opposite to change the most
Discrepancy
Would expect those with bigger discrepancies to move more toward a generate (or restudy) profile

(Expt vs. control, secondary analysis)
Cluster response types, and compare # of each type in expt vs. control
Taxonomy 1: short-short, short-long, long-short, long-long
Taxonomy 2: clustering with k-means

## Explore latency further, to try to explain results

```{r Explore latency over 20 items}


filter(df_v2n48_v3n36, !is.na(assessmentStrategyOrder)) %>% ggplot(aes(assessmentStrategyOrder, assessmentStrategyRevealLatency, color=prolificId)) +
  geom_point() + geom_smooth(se = FALSE) + 
  theme(legend.position = "none")


filter(df_v2n48_v3n36, !is.na(assessmentStrategyOrder)) %>% ggplot(aes(assessmentStrategyOrder, assessmentStrategyMoveOnLatency, color=prolificId)) +
  geom_point() + geom_smooth(se = FALSE) + 
  theme(legend.position = "none")

filter(df_v2n48_v3n36, !is.na(assessmentStrategyOrder)) %>% ggplot(aes(assessmentStrategyOrder, assessmentStrategyRevealLatency)) +
  geom_point() + geom_smooth(se = FALSE) + 
  theme(legend.position = "none")


filter(df_v2n48_v3n36, !is.na(assessmentStrategyOrder)) %>% ggplot(aes(assessmentStrategyOrder, assessmentStrategyMoveOnLatency)) +
  geom_point() + geom_smooth(se = FALSE) + 
  theme(legend.position = "none")

```
Latency decreases over the first 6 itmes or so, then plateaus around 2 sec, for both reveal and moveOn.

What if we take out the 0's and 5's?
```{r Explore latency over 20 items removing extremes}

filter(df_v2n48_v3n36, !is.na(assessmentStrategyOrder) & 
         !(assessmentStrategyRevealLatency == 0) & 
         !(assessmentStrategyRevealLatency >= 5000)) %>% ggplot(aes(assessmentStrategyOrder, assessmentStrategyRevealLatency)) +
  geom_point() + geom_smooth(se = FALSE) + 
  theme(legend.position = "none")


filter(df_v2n48_v3n36, !is.na(assessmentStrategyOrder)& 
         !(assessmentStrategyMoveOnLatency == 0) & 
         !(assessmentStrategyMoveOnLatency >= 5000)) %>% ggplot(aes(assessmentStrategyOrder, assessmentStrategyMoveOnLatency)) +
  geom_point() + geom_smooth(se = FALSE) + 
  theme(legend.position = "none")

```
When we take out the people who are arguably "passive", either skipping quickly (0 sec), or letting the time run (5 sec)...
For reveal, latency decreases steadily, from 2.4 sec to 1.5 sec. 
For moveOn, latency decreases over the first 7 items or so, then plateaus around 1.4 sec.

Hypotheses:
- retreival takes cognitive effort and people exert less and less of that over time
- review is passive, and people can consistely exert a steady amount of effort

? How long does the actual cognitive process take?
From pilot:
- retrieval: 2.5 secs to reveal, 2 secs to moveOn
- re-read: 1.4 secs to reveal, 2.4 secs to moveOn
- choice: 3 secs to reveal, 2.5 secs to moveOn

Hypotheses:
- when free choice, people use a unforcused, haphazard mix of strategies -> longer time
- when intentionally using a strategy -> shorter time

? What does latency mean?
- how to beliefs relate to latency? (effect of feedback)
- how does latency relate to performance? (assessment perf, controlling for intervention perf)

```{r what does latency correlate with?}

df_expt <- filter(df_v2n48_v3n36_users, condition=="expt")
df_control <- filter(df_v2n48_v3n36_users, condition=="control")

apa.cor.table(df_v2n48_v3n36_users[c(
  "avgAssessmentStrategyRevealLatency",
  "interventionTestRestudyScore",
  "interventionTestGenerateScore",
  "diff_score",
  "assessmentTestScore")])

apa.cor.table(df_v2n48_v3n36_users[c(
  "avgAssessmentStrategyMoveOnLatency",
  "interventionTestRestudyScore",
  "interventionTestGenerateScore",
  "diff_score",
  "assessmentTestScore")])


# expt only 
apa.cor.table(df_expt[c(
  "avgAssessmentStrategyRevealLatency",
  "interventionTestRestudyScore",
  "interventionTestGenerateScore",
  "diff_score",
  "assessmentTestScore")])

apa.cor.table(df_expt[c(
  "avgAssessmentStrategyMoveOnLatency",
  "interventionTestRestudyScore",
  "interventionTestGenerateScore",
  "diff_score",
  "assessmentTestScore")])

# control only 
apa.cor.table(df_control[c(
  "avgAssessmentStrategyRevealLatency",
  "interventionTestRestudyScore",
  "interventionTestGenerateScore",
  "diff_score",
  "assessmentTestScore")])

apa.cor.table(df_control[c(
  "avgAssessmentStrategyMoveOnLatency",
  "interventionTestRestudyScore",
  "interventionTestGenerateScore",
  "diff_score",
  "assessmentTestScore")])

```
Not a lot of revealing correlations...Could be that in the experimental group, the longer to reveal, the higher the assessmentTest score.



compare scores interv and assess
change assess to force 10 sec? (+distractor?)
or, reward learning?
```{r mean test scores}
mean(df_v2n48_v3n36_users$interventionTestScore, na.rm=T) # 6.8
mean(df_v2n48_v3n36_users$assessmentTestScore, na.rm=T) # 8.7
```
Assessment score is higher, so giving them ability to skip strategy doesn't seem to affect too many. Unless they're getting better at studying during the study phase?

Calculating actual scores
```{r Calculating actual feedback scores by group}

#3

# feedback
melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean",  interventionTestRestudyScore, interventionTestGenerateScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition","interventionOutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means

# outcomes
melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean",  assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition","interventionOutcome", "measures"), na.rm=TRUE, conf.interval=0.95); means

# do for n36
#, effectivenessChosenStrategy_num, effectivenessRestudy_num, effectivenessGenerate_num

#3x3?


```
## Investigating change in beliefs relative to predictions and outcomes

```{r abstract outcomes toward/away}

summary(lm(changeRelativeToOutcome_num ~ diff_interventionTestOutcomeRG, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.0007441
summary(lm(changeRelativeToOutcome_num ~ abs(diff_interventionTestOutcomeRG), filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.1011

summary(lm(changeRelativeToOutcome_num ~ diff_interventionRestudyScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.4
summary(lm(changeRelativeToOutcome_num ~ diff_interventionGenerateScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.6262
summary(lm(changeRelativeToOutcome_num ~ diff_interventionRestudyScoreToPrediction + diff_interventionGenerateScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.625

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(changeRelativeToOutcome_num)) %>% ggplot(aes(abs(diff_interventionTestOutcomeRG), changeRelativeToOutcome_num)) + geom_point() + geom_smooth(method=loess)

#which exceeded expectations more?

summary(lm(changeRelativeToOutcome_num ~ diff_interventionStrategyScoreExceedPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.3352
```

```{r CHANGE FILTERED 0 1 again in format consistent with other outcome measures}

summary(lm(changeRelativeToOutcome_num ~ abs(diff_interventionTestOutcomeRG), filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.1315
summary(lm(changeRelativeToOutcome_num ~ diff_interventionTestOutcomeRG, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.0003017

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(changeRelativeToOutcome_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, changeRelativeToOutcome_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(changeRelativeToOutcome_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, changeRelativeToOutcome_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=lm)


summary(lm(changeRelativeToOutcome_num ~ diff_interventionRestudyScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.09246 TREND
summary(lm(changeRelativeToOutcome_num ~ diff_interventionGenerateScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # n.s.
summary(lm(changeRelativeToOutcome_num ~ diff_interventionRestudyScoreToPrediction + diff_interventionGenerateScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.02332 SIG


filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(changeRelativeToOutcome_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, changeRelativeToOutcome_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(changeRelativeToOutcome_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, changeRelativeToOutcome_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=lm)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(changeRelativeToOutcome_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, changeRelativeToOutcome_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(changeRelativeToOutcome_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, changeRelativeToOutcome_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=lm)

#which exceeded expectations more?

summary(lm(changeRelativeToOutcome_num ~ diff_interventionStrategyScoreExceedPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.00615

summary(lm(changeRelativeToOutcome_num ~ abs(diff_interventionStrategyScoreExceedPrediction), filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.005985

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(changeRelativeToOutcome_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, changeRelativeToOutcome_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(changeRelativeToOutcome_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, changeRelativeToOutcome_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=lm)


# when both are in the model...but this prob doesn't make sense since correlated
summary(lm(changeRelativeToOutcome_num ~ diff_interventionTestOutcomeRG + diff_interventionStrategyScoreExceedPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.0008947

```

There's nearly a trend. The greater the discrepancy between reread and generate, the more likely they are to make a change that is consistent with the direction of the feedback. 

```{r abstract outcomes -2 -1 0 1 2}

summary(lm(directionOfChange_num ~ abs(diff_interventionTestOutcomeRG), filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.1315
summary(lm(directionOfChange_num ~ diff_interventionTestOutcomeRG, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.0003017

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(directionOfChange_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, directionOfChange_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(directionOfChange_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, directionOfChange_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=lm)


summary(lm(directionOfChange_num ~ diff_interventionRestudyScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.09246 TREND
summary(lm(directionOfChange_num ~ diff_interventionGenerateScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # n.s.
summary(lm(directionOfChange_num ~ diff_interventionRestudyScoreToPrediction + diff_interventionGenerateScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.02332 SIG


filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(directionOfChange_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, directionOfChange_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(directionOfChange_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, directionOfChange_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=lm)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(directionOfChange_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, directionOfChange_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(directionOfChange_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, directionOfChange_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=lm)

#which exceeded expectations more?

summary(lm(directionOfChange_num ~ diff_interventionStrategyScoreExceedPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.00615

summary(lm(directionOfChange_num ~ abs(diff_interventionStrategyScoreExceedPrediction), filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.005985

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(directionOfChange_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, directionOfChange_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(directionOfChange_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, directionOfChange_num)) + geom_jitter(width=.15, height=.15) + geom_smooth(method=lm)


# when both are in the model...but this prob doesn't make sense since correlated
summary(lm(directionOfChange_num ~ diff_interventionTestOutcomeRG + diff_interventionStrategyScoreExceedPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.0008947

```
Those who get generate are moving toward generate. Those who get restudy are moving toward equal/generate. 
The more the Restudy outcome exceeds the prediction, the less change toward feedback (more change away). If you do better than expected on Restudy, you move away from feedback, else you move toward feedback. 
The more the Generate outcome exceeds the prediction, the more change toward feedback. If you did better than expected on generate, you move toward feedback. Else if you did worse than expected on generate, you move toward or don't change in responses to feedback. 



```{r going back to simpler outcomes}

summary(lm(diff_assessmentBeliefRG_num ~ abs(diff_interventionTestOutcomeRG), filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.1194
summary(lm(diff_assessmentBeliefRG_num ~ diff_interventionTestOutcomeRG, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.008415

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(diff_assessmentBeliefRG_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, diff_assessmentBeliefRG_num)) + geom_point() + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(diff_assessmentBeliefRG_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, diff_assessmentBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)


summary(lm(diff_assessmentBeliefRG_num ~ diff_interventionRestudyScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # ns
summary(lm(diff_assessmentBeliefRG_num ~ diff_interventionGenerateScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # ns
summary(lm(diff_assessmentBeliefRG_num ~ diff_interventionRestudyScoreToPrediction + diff_interventionGenerateScoreToPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # ns


filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(diff_assessmentBeliefRG_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, diff_assessmentBeliefRG_num)) + geom_jitter() + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(diff_assessmentBeliefRG_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, diff_assessmentBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(diff_assessmentBeliefRG_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, diff_assessmentBeliefRG_num)) + geom_jitter() + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(diff_assessmentBeliefRG_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, diff_assessmentBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)

#which exceeded expectations more?

summary(lm(diff_assessmentBeliefRG_num ~ diff_interventionStrategyScoreExceedPrediction, filter(df_v2n48_v3n36_users, condition=="expt"))) # 0.4244

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(diff_assessmentBeliefRG_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, diff_assessmentBeliefRG_num)) + geom_point() + geom_smooth(method=loess)

filter(filter(df_v2n48_v3n36_users, condition=="expt"), !is.na(diff_assessmentBeliefRG_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, diff_assessmentBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)

```

```{r belief change as diff of z scores}

#df_v3n36_users$changeBeliefRG_num * df_v3n36_users$consis


summary(lm(changeBeliefRG_num ~ abs(diff_interventionTestOutcomeRG), df_v3n36_users)) # 0.05406
summary(lm(changeBeliefRG_num ~ diff_interventionTestOutcomeRG, df_v3n36_users)) # 0.149

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, changeBeliefRG_num)) + geom_point() + geom_smooth(method=loess)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)


summary(lm(changeBeliefRG_num ~ diff_interventionRestudyScoreToPrediction, df_v3n36_users)) # 0.005038
summary(lm(changeBeliefRG_num ~ diff_interventionGenerateScoreToPrediction, df_v3n36_users)) # .4054
summary(lm(changeBeliefRG_num ~ diff_interventionRestudyScoreToPrediction + diff_interventionGenerateScoreToPrediction, df_v3n36_users)) # 0.0005788


filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=loess)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=loess)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)

#which exceeded expectations more?

summary(lm(changeBeliefRG_num ~ diff_interventionStrategyScoreExceedPrediction, df_v3n36_users)) # 9.812e-05

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, changeBeliefRG_num)) + geom_point() + geom_smooth(method=loess)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)


```
# Testing effectiveness hypothesis
```{r mean effectiveness by preferred strategy (restudy, generate, choice)}

df_v3n36_users$effectivenessRestudy_num
df_v3n36_users$effectivenessGenerate_num
df_v3n36_users$effectivenessChosenStrategy_num

# lm(effectiveness ~ predicted by chosen, generate, or restudy)
# difference in means

melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(measures, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "measures", y = "mean effectiveness")

# split on preference for generate/restudy


melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("assessmentBelief", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(assessmentBelief, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentBelief", y = "mean effectiveness")

```

```{r mean effectiveness by strategy feedback (restudy, generate, choice)}

df_v3n36_users$effectivenessRestudy_num
df_v3n36_users$effectivenessGenerate_num
df_v3n36_users$effectivenessChosenStrategy_num

# lm(effectiveness ~ predicted by chosen, generate, or restudy)
# difference in means

melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(measures, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "measures", y = "mean effectiveness")

# split on preference for generate/restudy


melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("assessmentBelief", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(assessmentBelief, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentBelief", y = "mean effectiveness")

```
```{r verbal descriptions by strategy}

# mostly repeat, some word association, 2/8 recall (25%)
filter(df_v3n36_users, assessmentBelief=="restudy")$chosenStrategy

# word association, repeat, 4/14 recall (28%)
filter(df_v3n36_users, assessmentBelief=="generate")$chosenStrategy

# repeat, some word association, 1/12 recall (16%)
filter(df_v3n36_users, assessmentBelief=="equal")$chosenStrategy

# Descriptions are not really showing that people who "believe" generate are doing more generate

```

## Model comparison

```{r}

m0 <- lm(diff_assessmentBeliefRG_num ~ diff_interventionStrategyScoreExceedPrediction, df_v2n48_v3n36_users); summary(m0)

```


## Power analysis
```{r}

# beliefs
# behavior
# learning

# intervention vs. control

# means and errorbars, Latency means
melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "measures"), na.rm=TRUE, conf.interval=0.95); means

# reveal requires sample n=630-772
# moveOn requires sample n=16920-21396
# testScore requires sample n=5342-6122

# G, R, E vs. control

# means and errorbars, Latency means
melt <- tidyr::gather(df_v2n48_v3n36_users, key="measures", value="mean", avgAssessmentStrategyRevealLatency, avgAssessmentStrategyMoveOnLatency, assessmentTestScore, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("feedback", "measures"), na.rm=TRUE, conf.interval=0.95); means

# subset to G vs. control
# reveal requires sample n=4974-6296 /2/.6+183 = 4328-5429
# moveOn requires sample n=576-860 /2/.6+183 = 663-899
# testScore requires sample n=366-382 /2/.6+183 = 488-501


```

# Behavior analysis
```{r approximate behavioral buckets by >2 CLEAN UP IN PYTHON}

# approximate behavioral buckets
# df_v2n48_v3n36$assessmentStrategyGenerated
# df_v2n48_v3n36$assessmentStrategyRestudied
# df_v2n48_v3n36$assessmentStrategyGenerated_num
# df_v2n48_v3n36$assessmentStrategyRestudied_num
# df_v2n48_v3n36$assessmentStrategyNoneGenResBoth

# by condition

# messy analysis, "mean" which is % of time they used this strategy
melt <- tidyr::gather(df_v2n48_v3n36, key="measures", value="mean", assessmentStrategyGenerated_num, assessmentStrategyRestudied_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("prolificId", "condition", "measures"), na.rm=TRUE, conf.interval=0.95); means
means <- summarySE(melt, measurevar="mean", groupvars=c("condition", "measures"), na.rm=TRUE, conf.interval=0.95); means
# expt generated more, and restudied more

# table of strategy types
# divide by different n's: control n=420, expt n=1220
t <- table(assessmentStrategyNoneGenResBoth=df_v2n48_v3n36$assessmentStrategyNoneGenResBoth, condition=df_v2n48_v3n36$condition); t; addmargins(t)
scaledt <- sweep(t,2,colSums(t),`/`); scaledt
# expt generated more, and restudied more
# fewer expt did both
# fewer expt did neither

chisq.test(t) # p = 0.0001098
chisq.test(t(t)) # p = 0.0001098; doesn't matter if it's transposed
# sig, means distribution is different?
# reject the null hypothesis that latency profile is independent of condition

chisq.test(scaledt) # p = 0.9983
chisq.test(t(scaledt)) # p = 0.9983; doesn't matter if it's transposed
# n.s., means distribution is same?
# no, I think unequal sample size shouldn't matter; we're just looking at probability distributions...but then, why are the results changing?

# No this is wrong! looking at condition differences at item level, ignoring participant level. Need to aggregate into participants, before comparing condition differences.

ggplot(data.frame(scaledt)) +
  geom_bar(aes(x=assessmentStrategyNoneGenResBoth, y=Freq, fill=condition),
           stat="identity",
           position="dodge") +
  theme_bw()



# by FEEDBACK #########

# messy analysis, "mean" which is % of time they used this strategy
melt <- tidyr::gather(df_v2n48_v3n36, key="measures", value="mean", assessmentStrategyGenerated_num, assessmentStrategyRestudied_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("prolificId", "feedback", "measures"), na.rm=TRUE, conf.interval=0.95); means
means <- summarySE(melt, measurevar="mean", groupvars=c("feedback", "measures"), na.rm=TRUE, conf.interval=0.95); means
# expt generated more, and restudied more

# table of strategy types
# divide by different n's: control n=420, expt n=1220
t <- table(assessmentStrategyNoneGenResBoth=df_v2n48_v3n36$assessmentStrategyNoneGenResBoth, feedback=df_v2n48_v3n36$feedback); t; addmargins(t)
scaledt <- sweep(t,2,colSums(t),`/`); scaledt
# expt generated more, and restudied more
# fewer expt did both
# fewer expt did neither

chisq.test(t) # p =  2.2e-16
chisq.test(t(t)) # p =  2.2e-16; doesn't matter if it's transposed
# sig, means distribution is different?
# reject the null hypothesis that latency profile is independent of feedback

chisq.test(scaledt) # p = 1
chisq.test(t(scaledt)) # p = 1; doesn't matter if it's transposed
# n.s., means distribution is same?
# no, I think unequal sample size shouldn't matter; we're just looking at probability distributions...but then, why are the results changing?

# No this is wrong! looking at feedback differences at item level, ignoring participant level. Need to aggregate into participants, before comparing feedback differences.

ggplot(data.frame(scaledt)) +
  geom_bar(aes(x=assessmentStrategyNoneGenResBoth, y=Freq, fill=feedback),
           stat="identity",
           position="dodge") +
  theme_bw()


```

```{r belief change as diff of z scores}

#df_v3n36_users$changeBeliefRG_num * df_v3n36_users$consis


summary(lm(changeBeliefRG_num ~ abs(diff_interventionTestOutcomeRG), df_v3n36_users)) # 0.05406
summary(lm(changeBeliefRG_num ~ diff_interventionTestOutcomeRG, df_v3n36_users)) # 0.149

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, changeBeliefRG_num)) + geom_point() + geom_smooth(method=loess)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionTestOutcomeRG, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)


summary(lm(changeBeliefRG_num ~ diff_interventionRestudyScoreToPrediction, df_v3n36_users)) # 0.005038
summary(lm(changeBeliefRG_num ~ diff_interventionGenerateScoreToPrediction, df_v3n36_users)) # .4054
summary(lm(changeBeliefRG_num ~ diff_interventionRestudyScoreToPrediction + diff_interventionGenerateScoreToPrediction, df_v3n36_users)) # 0.0005788


filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=loess)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionRestudyScoreToPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=loess)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionGenerateScoreToPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)

#which exceeded expectations more?

summary(lm(changeBeliefRG_num ~ diff_interventionStrategyScoreExceedPrediction, df_v3n36_users)) # 9.812e-05

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, changeBeliefRG_num)) + geom_point() + geom_smooth(method=loess)

filter(df_v3n36_users, !is.na(changeBeliefRG_num)) %>% ggplot(aes(diff_interventionStrategyScoreExceedPrediction, changeBeliefRG_num)) + geom_jitter() + geom_smooth(method=lm)


```

# Testing effectiveness hypothesis
```{r mean effectiveness by preferred strategy (restudy, generate, choice)}

df_v3n36_users$effectivenessRestudy_num
df_v3n36_users$effectivenessGenerate_num
df_v3n36_users$effectivenessChosenStrategy_num

# lm(effectiveness ~ predicted by chosen, generate, or restudy)
# difference in means

melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(measures, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "measures", y = "mean effectiveness")

# split on preference for generate/restudy


melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("assessmentBelief", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(assessmentBelief, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentBelief", y = "mean effectiveness")

```

```{r mean effectiveness by strategy feedback (restudy, generate, choice)}

df_v3n36_users$effectivenessRestudy_num
df_v3n36_users$effectivenessGenerate_num
df_v3n36_users$effectivenessChosenStrategy_num

# lm(effectiveness ~ predicted by chosen, generate, or restudy)
# difference in means

melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(measures, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "measures", y = "mean effectiveness")

# split on preference for generate/restudy


melt <- tidyr::gather(df_v3n36_users, key="measures", value="mean", effectivenessRestudy_num, effectivenessGenerate_num, effectivenessChosenStrategy_num, factor_key = TRUE) # factor_key preserves order
means <- summarySE(melt, measurevar="mean", groupvars=c("assessmentBelief", "measures"), na.rm=TRUE, conf.interval=0.95); means
  
means %>% ggplot(aes(assessmentBelief, mean, color=measures, fill=measures)) + 
    geom_point(position=position_dodge(.9), stat="identity") + 
    geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.2, position=position_dodge(.9)) + 
    theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "assessmentBelief", y = "mean effectiveness")

```
```{r verbal descriptions by strategy}

# mostly repeat, some word association, 2/8 recall (25%)
filter(df_v3n36_users, assessmentBelief=="restudy")$chosenStrategy

# word association, repeat, 4/14 recall (28%)
filter(df_v3n36_users, assessmentBelief=="generate")$chosenStrategy

# repeat, some word association, 1/12 recall (16%)
filter(df_v3n36_users, assessmentBelief=="equal")$chosenStrategy

# Descriptions are not really showing that people who "believe" generate are doing more generate

```

# categorical and continuous predictors of beliefs
```{r categorical and continuous predictors of beliefs}

summary(lm(diff_assessmentBeliefRG_num ~ condition, df_v4n48_users)) # ns expt more generate

# diff from prediction add
summary(lm(diff_assessmentBeliefRG_num ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction add and interact
summary(lm(diff_assessmentBeliefRG_num ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction interact
summary(lm(diff_assessmentBeliefRG_num ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff RG add
summary(lm(diff_assessmentBeliefRG_num ~ condition + diff_interventionTestOutcomeRG, df_v4n48_users)) # ns 

# diff RG interact
summary(lm(diff_assessmentBeliefRG_num ~ condition * diff_interventionTestOutcomeRG, df_v4n48_users)) # trend p=0.05455; for expt condition, bigger difference RG means more final belief RG



## splitting diffs apart into raw scores

summary(lm(diff_assessmentBeliefRG_num ~ condition, df_v4n48_users)) # ns 

# diff from prediction add
summary(lm(diff_assessmentBeliefRG_num ~ condition + interventionPredictGenerate + interventionPredictRestudy + interventionTestGenerateScore + interventionTestRestudyScore, df_v4n48_users)) # ns 

# diff from prediction add and interact
summary(lm(diff_assessmentBeliefRG_num ~ condition * interventionPredictGenerate *  interventionTestGenerateScore + condition * interventionPredictRestudy * interventionTestRestudyScore, df_v4n48_users)) # ns , but maybe something interesting here

# diff from prediction interact
summary(lm(diff_assessmentBeliefRG_num ~ condition * interventionPredictGenerate *  interventionTestGenerateScore * interventionPredictRestudy * interventionTestRestudyScore, df_v4n48_users)) # ns 

# diff RG add
summary(lm(diff_assessmentBeliefRG_num ~ condition + interventionTestGenerateScore * interventionTestRestudyScore, df_v4n48_users)) # ns 

# diff RG interact
summary(lm(diff_assessmentBeliefRG_num ~ condition * interventionTestGenerateScore * interventionTestRestudyScore, df_v4n48_users)) # ns



```
# categorical and continuous predictors of behaviors
```{r categorical and continuous predictors of behaviors}


# avg reveal latency continuous

summary(lm(avgAssessmentStrategyRevealLatency ~ condition, df_v4n48_users)) # ns

summary(lm(avgAssessmentStrategyRevealLatency ~ condition * interventionPrediction, df_v4n48_users)) # ns
summary(lm(avgAssessmentStrategyRevealLatency ~ condition * interventionOutcome, df_v4n48_users)) # ns
summary(lm(avgAssessmentStrategyRevealLatency ~ condition * interventionPrediction*interventionOutcome, df_v4n48_users)) # ns


# diff from prediction add
summary(lm(avgAssessmentStrategyRevealLatency ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction add and interact
summary(lm(avgAssessmentStrategyRevealLatency ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction interact
summary(lm(avgAssessmentStrategyRevealLatency ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff RG add
summary(lm(avgAssessmentStrategyRevealLatency ~ condition + diff_interventionTestOutcomeRG, df_v4n48_users)) # ns 

# diff RG interact
summary(lm(avgAssessmentStrategyRevealLatency ~ condition * diff_interventionTestOutcomeRG, df_v4n48_users)) # ns




# avg moveOn latency continuous

summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition, df_v4n48_users)) # ns

summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition * interventionPrediction, df_v4n48_users)) # ns
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition * interventionOutcome, df_v4n48_users)) # ns
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition * interventionPrediction*interventionOutcome, df_v4n48_users)) # ns

# diff from prediction add
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction add and interact
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction interact
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff RG add
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition + diff_interventionTestOutcomeRG, df_v4n48_users)) # ns 

# diff RG interact
summary(lm(avgAssessmentStrategyMoveOnLatency ~ condition * diff_interventionTestOutcomeRG, df_v4n48_users)) # ns



# sd reveal latency continuous

summary(lm(sdAssessmentStrategyRevealLatency ~ condition, df_v4n48_users)) # ns

summary(lm(sdAssessmentStrategyRevealLatency ~ condition * interventionPrediction, df_v4n48_users)) # ns
summary(lm(sdAssessmentStrategyRevealLatency ~ condition * interventionOutcome, df_v4n48_users)) # ns
summary(lm(sdAssessmentStrategyRevealLatency ~ condition * interventionPrediction*interventionOutcome, df_v4n48_users)) # ns


# diff from prediction add
summary(lm(sdAssessmentStrategyRevealLatency ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction add and interact
summary(lm(sdAssessmentStrategyRevealLatency ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction interact
summary(lm(sdAssessmentStrategyRevealLatency ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff RG add
summary(lm(sdAssessmentStrategyRevealLatency ~ condition + diff_interventionTestOutcomeRG, df_v4n48_users)) # ns 

# diff RG interact
summary(lm(sdAssessmentStrategyRevealLatency ~ condition * diff_interventionTestOutcomeRG, df_v4n48_users)) # ns




# sd moveOn latency continuous

summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition, df_v4n48_users)) # ns

summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition * interventionPrediction, df_v4n48_users)) # ns
summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition * interventionOutcome, df_v4n48_users)) # approaching trend (equal and restudy have longer moveOn)
summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition * interventionPrediction*interventionOutcome, df_v4n48_users)) # approaching trend?

# diff from prediction add
summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction add and interact
summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction interact
summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff RG add
summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition + diff_interventionTestOutcomeRG, df_v4n48_users)) # approaching trend (more R>G at intervention, more sdMoveOn)

# diff RG interact
summary(lm(sdAssessmentStrategyMoveOnLatency ~ condition * diff_interventionTestOutcomeRG, df_v4n48_users)) # approaching trend?





# restudy how many continuous

summary(lm(howManyRestudy ~ condition, df_v4n48_users)) # ns

summary(lm(howManyRestudy ~ condition * interventionPrediction, df_v4n48_users)) # ns
summary(lm(howManyRestudy ~ condition * interventionOutcome, df_v4n48_users)) # ns
summary(lm(howManyRestudy ~ condition * interventionPrediction*interventionOutcome, df_v4n48_users)) # ns


# diff from prediction add
summary(lm(howManyRestudy ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction add and interact
summary(lm(howManyRestudy ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction interact
summary(lm(howManyRestudy ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff RG add
summary(lm(howManyRestudy ~ condition + diff_interventionTestOutcomeRG, df_v4n48_users)) # ns 

# diff RG interact
summary(lm(howManyRestudy ~ condition * diff_interventionTestOutcomeRG, df_v4n48_users)) # ns




# generate how many continuous

summary(lm(howManyGenerate ~ condition, df_v4n48_users)) # ns

summary(lm(howManyGenerate ~ condition * interventionPrediction, df_v4n48_users)) # ns
summary(lm(howManyGenerate ~ condition * interventionOutcome, df_v4n48_users)) # SIG
summary(lm(howManyGenerate ~ condition * interventionPrediction*interventionOutcome, df_v4n48_users)) # ns

# diff from prediction add
summary(lm(howManyGenerate ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction add and interact
summary(lm(howManyGenerate ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff from prediction interact
summary(lm(howManyGenerate ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # ns 

# diff RG add
summary(lm(howManyGenerate ~ condition + diff_interventionTestOutcomeRG, df_v4n48_users)) # ns 

# diff RG interact
summary(lm(howManyGenerate ~ condition * diff_interventionTestOutcomeRG, df_v4n48_users)) # TREND





```
```{r TODO how to actually lmer behaviors categorical}


# assessmentStrategyGenerated_num binary

summary(lmer(assessmentStrategyGenerated_num ~ condition + (1|prolificId), df_v4n48)) # ns
summary(lmer(assessmentStrategyGenerated_num ~ condition + (1|prolificId), df_v4n48, REML = FALSE)) # ns

summary(lmer(assessmentStrategyGenerated_num ~ condition * interventionPrediction + (1|prolificId), df_v4n48)) # ns
summary(lmer(assessmentStrategyGenerated_num ~ condition * interventionOutcome + (1|prolificId), df_v4n48)) # ns
summary(lmer(assessmentStrategyGenerated_num ~ condition * interventionPrediction*interventionOutcome + (1|prolificId), df_v4n48)) # ns

# diff from prediction add
summary(lmer(assessmentStrategyGenerated_num ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction + (1|prolificId), df_v4n48)) # ns 

summary(lmer(assessmentStrategyGenerated_num ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction + (1|prolificId), df_v4n48)) # ns 

# diff from prediction add and interact
summary(lmer(assessmentStrategyGenerated_num ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction  + (1|prolificId), df_v4n48)) # ns 

# diff from prediction interact
summary(lmer(assessmentStrategyGenerated_num ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction + (1|prolificId), df_v4n48)) # ns 

# diff RG add
summary(lmer(assessmentStrategyGenerated_num ~ condition + diff_interventionTestOutcomeRG + (1|prolificId), df_v4n48)) # ns 

# diff RG interact
summary(lmer(assessmentStrategyGenerated_num ~ condition * diff_interventionTestOutcomeRG + (1|prolificId), df_v4n48)) # ns


# assessmentStrategyRestudied_num binary

summary(lmer(assessmentStrategyRestudied_num ~ condition + (1|prolificId), df_v4n48)) # ns

summary(lmer(assessmentStrategyRestudied_num ~ condition * interventionPrediction + (1|prolificId), df_v4n48)) # ns
summary(lmer(assessmentStrategyRestudied_num ~ condition * interventionOutcome + (1|prolificId), df_v4n48)) # ns
summary(lmer(assessmentStrategyRestudied_num ~ condition * interventionPrediction*interventionOutcome + (1|prolificId), df_v4n48)) # ns

# diff from prediction add
summary(lmer(assessmentStrategyRestudied_num ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction + (1|prolificId), df_v4n48)) # ns 

summary(lmer(assessmentStrategyRestudied_num ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction + (1|prolificId), df_v4n48)) # ns 

# diff from prediction add and interact
summary(lmer(assessmentStrategyRestudied_num ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction  + (1|prolificId), df_v4n48)) # ns 

# diff from prediction interact
summary(lmer(assessmentStrategyRestudied_num ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction + (1|prolificId), df_v4n48)) # ns 

# diff RG add
summary(lmer(assessmentStrategyRestudied_num ~ condition + diff_interventionTestOutcomeRG + (1|prolificId), df_v4n48)) # ns 

# diff RG interact
summary(lmer(assessmentStrategyRestudied_num ~ condition * diff_interventionTestOutcomeRG + (1|prolificId), df_v4n48)) # ns




```
# continuous and categorical on learning outcomes
```{r continuous and categorical on learning outcomes}



# learning outcomes continuous

summary(lm(assessmentTestScore ~ condition, df_v4n48_users)) # ns

summary(lm(assessmentTestScore ~ condition * interventionPrediction, df_v4n48_users)) # ns
summary(lm(assessmentTestScore ~ condition * interventionOutcome, df_v4n48_users)) # SIG
summary(lm(assessmentTestScore ~ condition * interventionPrediction*interventionOutcome, df_v4n48_users)) # ns

# diff from prediction add
summary(lm(assessmentTestScore ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # sig 

# diff from prediction add and interact
summary(lm(assessmentTestScore ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # sig 

# diff from prediction interact
summary(lm(assessmentTestScore ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction, df_v4n48_users)) # sig 

# diff RG add
summary(lm(assessmentTestScore ~ condition + diff_interventionTestOutcomeRG, df_v4n48_users)) # ns 

# diff RG interact
summary(lm(assessmentTestScore ~ condition * diff_interventionTestOutcomeRG, df_v4n48_users)) # TREND


# learning outcomes continuous, ACCOUNTING for intevention test score

summary(lm(assessmentTestScore ~ condition + interventionTestScore, df_v4n48_users)) # ns

summary(lm(assessmentTestScore ~ condition * interventionPrediction + interventionTestScore, df_v4n48_users)) # ns
summary(lm(assessmentTestScore ~ condition * interventionOutcome + interventionTestScore, df_v4n48_users)) # ns
summary(lm(assessmentTestScore ~ condition * interventionPrediction*interventionOutcome + interventionTestScore, df_v4n48_users)) # ns

# diff from prediction add
summary(lm(assessmentTestScore ~ condition + diff_interventionGenerateScoreToPrediction + diff_interventionRestudyScoreToPrediction + interventionTestScore, df_v4n48_users)) # ns 

# diff from prediction add and interact
summary(lm(assessmentTestScore ~ condition * diff_interventionGenerateScoreToPrediction + condition * diff_interventionRestudyScoreToPrediction + interventionTestScore, df_v4n48_users)) # ns 

# diff from prediction interact
summary(lm(assessmentTestScore ~ condition * diff_interventionGenerateScoreToPrediction * diff_interventionRestudyScoreToPrediction + interventionTestScore, df_v4n48_users)) # ns 

# diff RG add
summary(lm(assessmentTestScore ~ condition + diff_interventionTestOutcomeRG + interventionTestScore, df_v4n48_users)) # ns 

# diff RG interact
summary(lm(assessmentTestScore ~ condition * diff_interventionTestOutcomeRG + interventionTestScore, df_v4n48_users)) # ns

# nothing else is significant when you put in interventionTestScores

```

